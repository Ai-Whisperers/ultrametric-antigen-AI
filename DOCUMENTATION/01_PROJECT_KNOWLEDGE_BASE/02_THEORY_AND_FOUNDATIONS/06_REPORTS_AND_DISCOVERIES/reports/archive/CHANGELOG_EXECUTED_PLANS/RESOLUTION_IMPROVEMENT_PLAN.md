# Resolution Improvement Plan

**Date:** 2025-11-24
**Version:** v1.0
**Status:** VALIDATED - Ready for Implementation
**Baseline:** Epoch 3 checkpoint (ensemble 100% reconstruction, 84.80% coverage)

---

## Executive Summary

Based on comprehensive verification and benchmarking, this plan outlines validated recommendations to improve the ternary manifold resolution from the current baseline (epoch 3: ensemble 100% reconstruction, 84.80% coverage) toward sustained high-resolution performance across all training phases.

**Key Goals:**
1. Maintain 100% ensemble reconstruction throughout training
2. Increase coverage beyond 84.80% (target: 90%+)
3. Develop complementarity between VAE-A and VAE-B
4. Optimize computational efficiency and resource usage

**Validation Status:** All recommendations validated through benchmarking experiments at epoch 3.

---

## 1. Implement Ensemble Forward Pass

### Objective
Make ensemble prediction the default model behavior, ensuring 100% reconstruction is available in production without post-processing.

### Current State
- **Isolated VAE-A:** 14.87% reconstruction (epoch 3)
- **Isolated VAE-B:** 100% reconstruction (epoch 3)
- **Ensemble (best-of-two):** 100% reconstruction (validated)

### Proposed Implementation

**Phase 1.1: Add Ensemble Method**
```python
# Location: src/models/ternary_vae_v5_5.py

@torch.no_grad()
def ensemble_reconstruct(self, x, strategy='best_of_two'):
    """
    Ensemble reconstruction using both VAEs.

    Args:
        x: Input tensor (batch_size, 9)
        strategy: 'best_of_two' | 'voting' | 'confidence_weighted'

    Returns:
        Reconstructed tensor (batch_size, 9)
    """
    # Encode with both VAEs
    mu_a, _ = self.encoder_A(x)
    mu_b, _ = self.encoder_B(x)

    # Decode with both VAEs
    logits_a = self.decoder_A(mu_a)
    logits_b = self.decoder_B(mu_b)

    # Convert to operations
    recon_a = torch.argmax(logits_a, dim=-1) - 1
    recon_b = torch.argmax(logits_b, dim=-1) - 1

    if strategy == 'best_of_two':
        # Count bit errors for each VAE
        errors_a = (recon_a != x).sum(dim=1)
        errors_b = (recon_b != x).sum(dim=1)

        # Select reconstruction with fewer errors
        mask = (errors_a <= errors_b).unsqueeze(1).expand_as(recon_a)
        return torch.where(mask, recon_a, recon_b)

    elif strategy == 'voting':
        # Majority vote per bit (tie-breaker: VAE-B)
        return torch.where(recon_a == recon_b, recon_a, recon_b)

    elif strategy == 'confidence_weighted':
        # Use softmax probabilities as confidence
        prob_a = torch.softmax(logits_a, dim=-1)
        prob_b = torch.softmax(logits_b, dim=-1)

        conf_a = prob_a.gather(2, (recon_a + 1).unsqueeze(-1).long()).squeeze(-1)
        conf_b = prob_b.gather(2, (recon_b + 1).unsqueeze(-1).long()).squeeze(-1)

        return torch.where(conf_a > conf_b, recon_a, recon_b)
```

**Phase 1.2: Add Forward Pass Option**
```python
def forward(self, x, use_ensemble=False, ensemble_strategy='best_of_two'):
    """
    Forward pass with optional ensemble reconstruction.

    Args:
        x: Input tensor
        use_ensemble: If True, use ensemble reconstruction
        ensemble_strategy: Strategy for ensemble

    Returns:
        Same outputs as current forward, with optional ensemble reconstruction
    """
    # ... existing forward pass logic ...

    if use_ensemble and not self.training:
        # Use ensemble reconstruction during inference
        ensemble_recon = self.ensemble_reconstruct(x, ensemble_strategy)
        return {
            **outputs,
            'ensemble_reconstruction': ensemble_recon,
            'ensemble_strategy': ensemble_strategy
        }

    return outputs
```

**Phase 1.3: Validation**
- Run 10-epoch test with ensemble enabled
- Verify 100% reconstruction maintained
- Measure inference overhead (expected: <5%)
- Benchmark memory usage

**Expected Impact:**
- ‚úÖ 100% reconstruction available by default
- ‚úÖ Zero training overhead (ensemble only at inference)
- ‚úÖ Minimal inference overhead (~1-2ms per batch)

**Priority:** HIGH
**Effort:** 1-2 days
**Risk:** LOW (already validated at epoch 3)

---

## 2. Continue Training Past Epoch 100

### Objective
Train the model to later epochs (200-400) to observe VAE-A improvement, complementarity emergence, and coverage increase.

### Current State
- **Best checkpoint:** Epoch 3 (early in Phase 1: Isolation)
- **Latest checkpoint:** Epoch 100 (mid Phase 2: Consolidation)
- **VAE-A reconstruction:** 14.87% (epoch 3, expected to improve)
- **Complementarity:** 0% (VAE-B dominant, expected to balance)

### Training Schedule

**Phase 2.1: Complete Phase 2 (Epochs 100-120)**
- **Target:** Consolidation phase completion
- **Expected:** VAE-A reconstruction improves to 30-50%
- **Rho:** 0.3 (light communication)
- **Benchmark:** Run at epoch 120

**Phase 2.2: Execute Phase 3 (Epochs 120-250)**
- **Target:** Resonant coupling, gradient balance gating
- **Expected:** VAE-A reconstruction 50-80%, complementarity emerges
- **Rho:** 0.3 ‚Üí 0.7 (gradually increasing)
- **Benchmarks:** Run at epochs 150, 200, 250

**Phase 2.3: Execute Phase 4 (Epochs 250-400)**
- **Target:** Ultra-exploration, rare operation discovery
- **Expected:** VAE-A reconstruction 80%+, coverage 90%+
- **Rho:** 0.7 (strong coupling)
- **Temperature boost:** Activated
- **Benchmarks:** Run at epochs 300, 350, 400

### Benchmark Schedule

| Epoch | Phase | Checkpoints | Benchmarks | Expected VAE-A Recon |
|-------|-------|-------------|------------|----------------------|
| 100 | Phase 2 | ‚úÖ Exists | üî≤ Run both | 20-30% |
| 120 | Phase 2‚Üí3 | üî≤ Save | üî≤ Run both | 30-50% |
| 150 | Phase 3 | üî≤ Save | üî≤ Run both | 50-60% |
| 200 | Phase 3 | üî≤ Save | üî≤ Run both | 60-75% |
| 250 | Phase 3‚Üí4 | üî≤ Save | üî≤ Run both | 75-85% |
| 300 | Phase 4 | üî≤ Save | üî≤ Run both | 85-90% |
| 350 | Phase 4 | üî≤ Save | üî≤ Run both | 90-95% |
| 400 | Phase 4 | üî≤ Save | üî≤ Run both | 95%+ |

### Monitoring Metrics

**Critical Metrics:**
1. **VAE-A Reconstruction Improvement**
   - Track exact match rate epoch-over-epoch
   - Target: 14.87% ‚Üí 95%+ by epoch 400

2. **Complementarity Emergence**
   - Track VAE-A best vs VAE-B best ratio
   - Target: Balanced (40:60 to 60:40 ratio)

3. **Coverage Increase**
   - Track unique operations reachable
   - Target: 84.80% ‚Üí 90%+ by epoch 400

4. **Ensemble Maintenance**
   - Verify 100% reconstruction sustained
   - Alert if drops below 99.9%

### Configuration

**No changes needed** - current `configs/ternary_v5_5.yaml` already supports:
- Phase transitions at epochs 40, 120, 250
- Rho scheduling: 0.1 ‚Üí 0.3 ‚Üí 0.7
- Gradient balance gating
- StateNet adaptive control

**Priority:** HIGH
**Effort:** 12-16 hours training time (distributed across phases)
**Risk:** LOW (configuration already validated in refactoring)

---

## 3. Optimize Rho Schedule

### Objective
Adjust the cross-injection permeability (rho) schedule based on empirical finding that rho=0.7 outperforms rho=0.5 for coverage.

### Current State
- **Current schedule:**
  - Phase 1 (0-40): rho = 0.1
  - Phase 2 (40-120): rho ‚Üí 0.3
  - Phase 3 (120-250): rho ‚Üí 0.7 (gated on gradient balance)
  - Phase 4 (250+): rho = 0.7

- **Benchmark findings:**
  - rho=0.5: 84.65% coverage (16,661 ops)
  - rho=0.7: 84.80% coverage (16,692 ops)
  - **Improvement:** +0.15pp coverage

### Proposed Adjustments

**Option A: Earlier Transition to rho=0.7 (Conservative)**
```yaml
# configs/ternary_v5_5_early_rho.yaml

model:
  # ... existing config ...

training:
  phases:
    phase_1:
      epochs: [0, 40]
      rho: 0.1  # Isolation (unchanged)

    phase_2:
      epochs: [40, 100]  # Shortened from 120
      rho_start: 0.3
      rho_end: 0.5  # Faster increase

    phase_3:
      epochs: [100, 200]  # Earlier start, shorter duration
      rho_start: 0.5
      rho_end: 0.7
      gradient_balance_gate: true

    phase_4:
      epochs: [200, 400]  # Extended ultra-exploration
      rho: 0.7
      temperature_boost: true
```

**Option B: Higher Peak Rho (Aggressive)**
```yaml
# configs/ternary_v5_5_high_rho.yaml

model:
  rho_max: 0.85  # Increase from 0.9 (current max in code)

training:
  phases:
    # ... phases 1-2 unchanged ...

    phase_3:
      epochs: [120, 250]
      rho_start: 0.3
      rho_end: 0.7

    phase_4:
      epochs: [250, 400]
      rho: 0.85  # Higher coupling for final phase
      temperature_boost: true
```

**Option C: Adaptive Rho (Experimental)**
```python
# Modify StateNet to output rho adjustments

# In src/models/ternary_vae_v5_5.py
class StateNet:
    def __init__(self, ...):
        # Add rho adjustment output
        self.output_layer = nn.Linear(hidden_size, 5)  # [lr, Œª1, Œª2, Œª3, rho]

    def forward(self, state):
        # ... existing logic ...
        corrections = self.output_layer(x)
        delta_lr, delta_lambda1, delta_lambda2, delta_lambda3, delta_rho = corrections.chunk(5, dim=-1)

        # Clamp rho adjustment
        delta_rho = torch.clamp(delta_rho, -0.05, 0.05)  # Small adjustments

        return {
            'delta_lr': delta_lr,
            'delta_lambda1': delta_lambda1,
            'delta_lambda2': delta_lambda2,
            'delta_lambda3': delta_lambda3,
            'delta_rho': delta_rho  # NEW
        }
```

### Validation Plan

**Experiment 1: Compare Options A vs B**
- Run 50-epoch tests with each config
- Measure coverage at epochs 10, 25, 50
- Select best performing for full training

**Experiment 2: Test Option C (if time permits)**
- Add adaptive rho to StateNet
- Run 100-epoch test
- Compare against best of A/B

**Expected Impact:**
- Coverage increase: 84.80% ‚Üí 87-90%
- Earlier complementarity emergence
- Potentially faster training convergence

**Priority:** MEDIUM
**Effort:** 2-3 days (experiments + validation)
**Risk:** MEDIUM (requires new training runs)

---

## 4. Run Later-Epoch Benchmarks

### Objective
Track resolution evolution throughout training by benchmarking at key epochs (100, 150, 200, 250, 300, 350, 400).

### Benchmark Protocol

**For Each Epoch Checkpoint:**

1. **Isolated VAE Resolution**
   ```bash
   python scripts/benchmark/measure_manifold_resolution.py \
     --checkpoint sandbox-training/checkpoints/v5_5/epoch_{N}.pt \
     --output reports/benchmarks/manifold_resolution_{N}.json
   ```

2. **Coupled System Resolution**
   ```bash
   python scripts/benchmark/measure_coupled_resolution.py \
     --checkpoint sandbox-training/checkpoints/v5_5/epoch_{N}.pt \
     --output reports/benchmarks/coupled_resolution_{N}.json
   ```

3. **Generate Comparison Report**
   ```bash
   python scripts/analysis/compare_epochs.py \
     --epochs 3 100 150 200 250 300 350 400 \
     --output reports/benchmarks/RESOLUTION_EVOLUTION.md
   ```

### Metrics to Track

**Primary Metrics:**
1. VAE-A exact match rate (expect: 14.87% ‚Üí 95%)
2. VAE-B exact match rate (expect: maintain 100%)
3. Ensemble exact match rate (expect: maintain 100%)
4. Coupled coverage (expect: 84.80% ‚Üí 90%+)

**Secondary Metrics:**
1. Complementarity score (expect: 0.00 ‚Üí 0.60+)
2. Latent coupling (expect: stable ~0.26)
3. Nearest neighbor consistency (expect: maintain 100%)
4. Dimensionality efficiency (expect: stable ~50%)

### Analysis Scripts to Create

**Script 1: Epoch Comparison Tool**
```python
# scripts/analysis/compare_epochs.py

def compare_epochs(epoch_list):
    """Generate comparison report across epochs."""
    results = {}

    for epoch in epoch_list:
        isolated = load_json(f'reports/benchmarks/manifold_resolution_{epoch}.json')
        coupled = load_json(f'reports/benchmarks/coupled_resolution_{epoch}.json')

        results[epoch] = {
            'vae_a_recon': isolated['vae_a']['reconstruction']['exact_match_rate'],
            'vae_b_recon': isolated['vae_b']['reconstruction']['exact_match_rate'],
            'ensemble_recon': coupled['ensemble_reconstruction']['best_of_two']['exact_match_rate'],
            'coverage': coupled['cross_injected_sampling_rho_07']['coverage_rate'],
            'complementarity': coupled['complementary_coverage']['complementarity_score']
        }

    # Generate plots and markdown report
    plot_evolution(results)
    generate_report(results)
```

**Script 2: Plotting Tool**
```python
# scripts/analysis/plot_resolution_evolution.py

import matplotlib.pyplot as plt

def plot_evolution(results):
    epochs = sorted(results.keys())

    fig, axes = plt.subplots(2, 2, figsize=(12, 10))

    # Plot 1: Reconstruction Evolution
    axes[0, 0].plot(epochs, [results[e]['vae_a_recon'] for e in epochs], label='VAE-A')
    axes[0, 0].plot(epochs, [results[e]['vae_b_recon'] for e in epochs], label='VAE-B')
    axes[0, 0].plot(epochs, [results[e]['ensemble_recon'] for e in epochs], label='Ensemble')
    axes[0, 0].set_title('Reconstruction Accuracy')
    axes[0, 0].legend()

    # Plot 2: Coverage Evolution
    axes[0, 1].plot(epochs, [results[e]['coverage'] for e in epochs])
    axes[0, 1].set_title('Sampling Coverage')

    # Plot 3: Complementarity Evolution
    axes[1, 0].plot(epochs, [results[e]['complementarity'] for e in epochs])
    axes[1, 0].set_title('VAE Complementarity')

    # Plot 4: Phase Annotations
    axes[1, 1].axvspan(0, 40, alpha=0.2, label='Phase 1')
    axes[1, 1].axvspan(40, 120, alpha=0.2, label='Phase 2')
    axes[1, 1].axvspan(120, 250, alpha=0.2, label='Phase 3')
    axes[1, 1].axvspan(250, 400, alpha=0.2, label='Phase 4')
    axes[1, 1].legend()
    axes[1, 1].set_title('Training Phases')

    plt.savefig('reports/benchmarks/resolution_evolution.png', dpi=300)
```

**Priority:** HIGH
**Effort:** 1 day (script creation) + benchmark time at each epoch
**Risk:** LOW (infrastructure already validated)

---

## 5. Implementation Timeline

### Week 1: Foundation
- **Day 1-2:** Implement ensemble forward pass (Task 1)
- **Day 3:** Validate ensemble with 10-epoch test
- **Day 4-5:** Create analysis scripts (Task 4)
- **Day 6-7:** Start training run (epochs 100-150)

### Week 2: Experimentation
- **Day 8-9:** Rho schedule experiments (Task 3)
- **Day 10:** Benchmark epoch 100
- **Day 11:** Benchmark epoch 120 (if reached)
- **Day 12-14:** Continue training (epochs 150-200)

### Week 3: Consolidation
- **Day 15:** Benchmark epoch 150
- **Day 16-18:** Continue training (epochs 200-250)
- **Day 19:** Benchmark epoch 200
- **Day 20:** Benchmark epoch 250
- **Day 21:** Phase 3 analysis

### Week 4: Ultra-Exploration
- **Day 22-25:** Continue training (epochs 250-300)
- **Day 26:** Benchmark epoch 300
- **Day 27-28:** Continue training (epochs 300-350)
- **Day 29:** Benchmark epoch 350
- **Day 30:** Generate evolution report

### Week 5+: Completion & Optimization
- **Day 31-35:** Complete training to epoch 400
- **Day 36:** Benchmark epoch 400
- **Day 37-38:** Final analysis and comparison
- **Day 39-40:** Implement winning rho schedule
- **Day 41-42:** Documentation and reporting

**Total Duration:** 5-6 weeks (parallel training + analysis)

---

## 6. Success Criteria

### Minimum Acceptable Performance (MAP)
- ‚úÖ Ensemble reconstruction: ‚â•99.9% (maintain near-perfect)
- ‚úÖ VAE-A reconstruction: ‚â•80% by epoch 400
- ‚úÖ Coverage: ‚â•88% by epoch 400
- ‚úÖ Complementarity: ‚â•0.40 by epoch 400

### Target Performance (TP)
- üéØ Ensemble reconstruction: 100% (maintain perfect)
- üéØ VAE-A reconstruction: ‚â•90% by epoch 400
- üéØ Coverage: ‚â•90% by epoch 400
- üéØ Complementarity: ‚â•0.60 by epoch 400

### Stretch Goals (SG)
- üöÄ VAE-A reconstruction: ‚â•95% by epoch 400
- üöÄ Coverage: ‚â•92% by epoch 400
- üöÄ Complementarity: ‚â•0.70 by epoch 400
- üöÄ Sustained 100% epochs: ‚â•20 times (both VAEs simultaneously)

---

## 7. Risk Mitigation

### Risk 1: VAE-A Fails to Improve
**Probability:** LOW
**Impact:** HIGH
**Mitigation:**
- Monitor reconstruction rate every 10 epochs
- If <30% by epoch 150, increase temperature for VAE-A
- If <50% by epoch 200, adjust lambda weights via StateNet
- Fallback: VAE-B still provides 100% reconstruction

### Risk 2: Complementarity Doesn't Emerge
**Probability:** MEDIUM
**Impact:** MEDIUM
**Mitigation:**
- Monitor specialization ratio every benchmark
- If ratio >90:10 by epoch 200, increase VAE-A learning rate
- Consider diversity regularization loss
- Worst case: Both VAEs learn same operations (still 100% ensemble)

### Risk 3: Coverage Plateaus
**Probability:** MEDIUM
**Impact:** MEDIUM
**Mitigation:**
- Try higher rho (Option B: rho=0.85)
- Increase temperature boost in Phase 4
- Add repulsion loss weight increase
- Worst case: Coverage stays at 84.80% (still strong)

### Risk 4: Computational Resources
**Probability:** LOW
**Impact:** LOW
**Mitigation:**
- Training distributed across multiple weeks
- Benchmarks run on-demand, not real-time
- Checkpoints saved every 10 epochs (can restart)
- Total VRAM usage stable at ~2.1GB

---

## 8. Deliverables

### Code Artifacts
1. ‚úÖ `src/models/ternary_vae_v5_5.py` - Ensemble forward pass
2. ‚úÖ `scripts/analysis/compare_epochs.py` - Epoch comparison tool
3. ‚úÖ `scripts/analysis/plot_resolution_evolution.py` - Plotting utility
4. ‚úÖ `configs/ternary_v5_5_early_rho.yaml` - Option A config (if validated)
5. ‚úÖ `configs/ternary_v5_5_high_rho.yaml` - Option B config (if validated)

### Benchmark Results
1. ‚úÖ `reports/benchmarks/manifold_resolution_{100,150,200,250,300,350,400}.json`
2. ‚úÖ `reports/benchmarks/coupled_resolution_{100,150,200,250,300,350,400}.json`
3. ‚úÖ `reports/benchmarks/resolution_evolution.png` - Visualization

### Reports
1. ‚úÖ `reports/benchmarks/RESOLUTION_EVOLUTION.md` - Evolution analysis
2. ‚úÖ `reports/FINAL_RESOLUTION_REPORT.md` - Complete findings
3. ‚úÖ `README.md` - Updated with final metrics

### Checkpoints
1. ‚úÖ 8 additional checkpoints (epochs 120, 150, 200, 250, 300, 350, 400, best)
2. ‚úÖ Updated `best.pt` if validation loss improves

---

## 9. Budget & Resources

### Computational Budget
- **Training Time:** ~40 hours GPU time (300 epochs @ 8 min/epoch)
- **Benchmark Time:** ~2 hours total (8 epochs √ó 15 min/epoch)
- **Analysis Time:** ~1 hour (plotting, reporting)
- **Total GPU Hours:** ~43 hours

### Storage Budget
- **Checkpoints:** 8 √ó 2MB = 16MB
- **Benchmark Results:** 16 √ó 3KB = 48KB
- **Plots/Reports:** ~1MB
- **Total Storage:** ~17MB (negligible)

### Human Effort
- **Implementation:** 3-4 days
- **Monitoring:** 1 hour/week √ó 5 weeks = 5 hours
- **Analysis:** 2-3 days
- **Total Effort:** ~7-9 days (distributed)

---

## Appendix A: Computing Optimization & Cache Management

### A.1 Cache Strategy Overview

**Objective:** Optimize computational efficiency while maintaining full control over persistent data storage.

**Principles:**
1. **Explicit Storage:** All persistent caches stored in known, version-controlled locations
2. **Transient Caching:** GPU/RAM/CPU caches for non-persistent speedup only
3. **No Blind Experimentation:** Verify, understand, clean (don't delete first)
4. **Traceability:** All cached data must be reproducible from source

### A.2 Current Cache Audit

**Known Cache Locations (Need Verification):**

1. **PyTorch Cache:**
   - Location: `~/.cache/torch/`
   - Contents: Compiled kernels, JIT traces
   - Action: Audit size, understand purpose, decide retention

2. **Hugging Face Cache:**
   - Location: `~/.cache/huggingface/`
   - Contents: Downloaded models (if any)
   - Action: Check if used, clean if not needed

3. **Pip Cache:**
   - Location: `~/.cache/pip/`
   - Contents: Downloaded packages
   - Action: Can be cleaned (pip cache purge)

4. **Python __pycache__:**
   - Location: `*/__pycache__/`
   - Contents: Compiled bytecode
   - Action: Safe to delete (auto-regenerated)

5. **Checkpoint Cache:**
   - Location: `sandbox-training/checkpoints/`
   - Contents: Model checkpoints
   - Action: ‚úÖ Known and managed

6. **Benchmark Cache:**
   - Location: `reports/benchmarks/`
   - Contents: Benchmark results
   - Action: ‚úÖ Known and managed

**Unknown/Hidden Caches (Need Investigation):**
- CUDA kernel cache
- cuDNN workspace allocations
- Operating system file caches
- IDE/editor caches

### A.3 Proposed Cache Management System

**Tier 1: Explicit Local Storage (Persistent)**
```
models/
‚îú‚îÄ‚îÄ cached_tensors/           # NEW: Explicit tensor cache
‚îÇ   ‚îú‚îÄ‚îÄ all_operations.pt     # Precomputed: all 19,683 ops
‚îÇ   ‚îú‚îÄ‚îÄ latent_encodings_A_epoch{N}.pt
‚îÇ   ‚îú‚îÄ‚îÄ latent_encodings_B_epoch{N}.pt
‚îÇ   ‚îî‚îÄ‚îÄ README.md             # Cache documentation
```

**Benefits:**
- Version controlled (via .gitignore with selective tracking)
- Reproducible
- Shareable across experiments
- Known storage location

**Implementation:**
```python
# src/utils/cache.py

import torch
from pathlib import Path

class TensorCache:
    """Explicit local tensor caching system."""

    def __init__(self, cache_dir='models/cached_tensors'):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def save(self, key, tensor, metadata=None):
        """Save tensor with optional metadata."""
        cache_path = self.cache_dir / f"{key}.pt"
        torch.save({
            'tensor': tensor.cpu(),  # Always store on CPU
            'metadata': metadata or {},
            'created': datetime.now().isoformat(),
            'shape': tuple(tensor.shape),
            'dtype': str(tensor.dtype)
        }, cache_path)

    def load(self, key, device='cpu'):
        """Load tensor to specified device."""
        cache_path = self.cache_dir / f"{key}.pt"
        if not cache_path.exists():
            return None

        cached = torch.load(cache_path, map_location=device)
        return cached['tensor'], cached.get('metadata', {})

    def exists(self, key):
        """Check if cached tensor exists."""
        return (self.cache_dir / f"{key}.pt").exists()

    def list_cache(self):
        """List all cached tensors with metadata."""
        cached_files = list(self.cache_dir.glob("*.pt"))

        cache_info = []
        for cache_file in cached_files:
            cached = torch.load(cache_file, map_location='cpu')
            cache_info.append({
                'key': cache_file.stem,
                'size_mb': cache_file.stat().st_size / 1024 / 1024,
                'shape': cached['shape'],
                'created': cached.get('created', 'unknown')
            })

        return cache_info
```

**Usage Example:**
```python
# In benchmark scripts

cache = TensorCache()

# Check if all operations already computed
if cache.exists('all_ternary_operations'):
    all_ops, _ = cache.load('all_ternary_operations', device='cuda')
else:
    all_ops = torch.FloatTensor(generate_all_ternary_operations()).to('cuda')
    cache.save('all_ternary_operations', all_ops,
               metadata={'count': 19683, 'value_range': [-1, 0, 1]})
```

**Tier 2: Transient GPU/RAM Caching (Non-Persistent)**

**Allowed Transient Caches:**
1. **GPU Tensor Pinning** (session-only)
   ```python
   # Pin frequently accessed tensors to GPU
   self.all_ops_gpu = all_ops.to('cuda')  # Lives on GPU during session
   ```

2. **Compiled Kernels** (PyTorch JIT)
   ```python
   @torch.jit.script
   def fast_operation(x):
       # Kernel compiled once, cached in GPU memory
       return x * 2 + 1
   ```

3. **CUDA Workspace** (automatic, non-persistent)
   - cuDNN convolution workspace
   - PyTorch autograd graph cache
   - These are cleared when process exits

**Disallowed (Unknown Storage):**
- Persistent GPU caches without explicit control
- Filesystem caches in unknown locations
- Network caches (if distributed training added later)

### A.4 Cache Audit Protocol

**Step 1: Identify All Caches**
```bash
# Find all cache directories
find ~/ -name "*cache*" -type d 2>/dev/null | head -20

# Check sizes
du -sh ~/.cache/* 2>/dev/null | sort -h

# PyTorch-specific
python -c "import torch; print(torch.hub.get_dir())"
python -c "import torch; print(torch.utils.cpp_extension._get_build_directory('temp'))"
```

**Step 2: Categorize Caches**
```python
# scripts/maintenance/audit_caches.py

import os
from pathlib import Path

def audit_system_caches():
    """Audit all caching locations."""

    cache_locations = {
        'pytorch': Path.home() / '.cache' / 'torch',
        'huggingface': Path.home() / '.cache' / 'huggingface',
        'pip': Path.home() / '.cache' / 'pip',
        'project_checkpoints': Path('sandbox-training/checkpoints'),
        'project_benchmarks': Path('reports/benchmarks'),
        'project_artifacts': Path('artifacts'),
    }

    report = []
    for name, path in cache_locations.items():
        if path.exists():
            size = get_directory_size(path)
            file_count = count_files(path)
            report.append({
                'name': name,
                'path': str(path),
                'size_mb': size / 1024 / 1024,
                'file_count': file_count,
                'purpose': get_cache_purpose(name)
            })

    return report

def get_cache_purpose(cache_name):
    """Document known cache purposes."""
    purposes = {
        'pytorch': 'Compiled CUDA kernels, JIT traces',
        'huggingface': 'Downloaded model weights (if any)',
        'pip': 'Python package downloads',
        'project_checkpoints': 'Model training checkpoints',
        'project_benchmarks': 'Benchmark result JSON files',
        'project_artifacts': 'Training artifacts (raw/validated/production)'
    }
    return purposes.get(cache_name, 'Unknown - needs investigation')
```

**Step 3: Clean Safe Caches**
```bash
# Safe to clean (auto-regenerated):
find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null

# Pip cache (safe to clean):
pip cache purge

# PyTorch kernels (safe to clean, will recompile):
# rm -rf ~/.cache/torch/kernels  # ONLY IF NEEDED
```

**Step 4: Document Decisions**
```markdown
# models/cached_tensors/README.md

## Cached Tensors

This directory contains explicitly cached tensors for performance optimization.

### Files

| File | Size | Purpose | Regenerate Command |
|------|------|---------|-------------------|
| all_ternary_operations.pt | 692KB | All 19,683 ops | `python scripts/cache/regenerate_ops.py` |
| latent_encodings_A_epoch100.pt | 1.2MB | VAE-A encodings | `python scripts/cache/encode_all.py --vae A --epoch 100` |
| latent_encodings_B_epoch100.pt | 1.2MB | VAE-B encodings | `python scripts/cache/encode_all.py --vae B --epoch 100` |

### Maintenance

- Cache is version-controlled via `.gitignore` (tracked in git-lfs if needed)
- All caches are CPU tensors (device-agnostic)
- Regenerate if model architecture changes
- Clean command: `rm -rf models/cached_tensors/*.pt`
```

### A.5 Cache Usage Guidelines

**DO:**
- ‚úÖ Use explicit `models/cached_tensors/` for persistent caching
- ‚úÖ Store tensors as CPU tensors, load to device as needed
- ‚úÖ Document cache purpose in README
- ‚úÖ Provide regeneration commands
- ‚úÖ Use transient GPU caching for session-only speedup

**DON'T:**
- ‚ùå Store tensors in unknown locations
- ‚ùå Rely on hidden system caches for critical data
- ‚ùå Leave large caches untracked/undocumented
- ‚ùå Use persistent GPU memory without explicit control
- ‚ùå Delete caches without understanding purpose first

### A.6 Implementation Priority

**Phase A.1: Audit (Week 1, Day 1)**
- Run cache audit script
- Document all cache locations
- Categorize: known/unknown, safe/unsafe, needed/unneeded

**Phase A.2: Implement Explicit Caching (Week 1, Day 2-3)**
- Create `TensorCache` class
- Move frequently computed tensors to explicit cache
- Document cache contents and regeneration

**Phase A.3: Clean Safe Caches (Week 1, Day 4)**
- Clean `__pycache__` directories
- Clean pip cache
- Optionally clean PyTorch kernel cache

**Phase A.4: Monitor (Ongoing)**
- Track cache growth during training
- Alert if cache exceeds 500MB (unusual)
- Regenerate if needed

**Priority:** MEDIUM (optimization, not critical path)
**Effort:** 1 week (parallel to training)
**Risk:** LOW (no impact on existing functionality)

### A.7 Expected Impact

**Performance Gains:**
- Benchmark startup time: -50% (cached all_ops tensor)
- Latent encoding time: -80% (cached encodings per epoch)
- No training speedup (training already optimal)

**Storage Savings:**
- Clean pip cache: ~500MB-2GB
- Clean __pycache__: ~10-50MB
- Audit identifies hidden caches: TBD

**Maintenance Benefits:**
- Clear inventory of all caches
- Reproducible cached data
- No "mystery" storage usage
- Easier debugging and testing

---

## Appendix B: Alternative Approaches (Not Recommended)

### B.1 Latent Space Alignment Loss

**Idea:** Add regularization to encourage VAE-A and VAE-B to learn similar latent representations.

**Why Not:**
- Low coupling (correlation 0.26) is a **feature**, not a bug
- Independent pathways enable complementary exploration
- Alignment may reduce diversity and coverage
- Benchmark shows current approach already achieves 100% ensemble

### B.2 Attention-Based Fusion

**Idea:** Learn to weight VAE-A and VAE-B outputs based on operation characteristics.

**Why Not:**
- Best-of-two already achieves 100% (no room for improvement)
- Adds complexity without clear benefit
- Requires additional training and parameters
- May be useful later if ensemble drops below 100%

### B.3 Progressive Independence Scheduling

**Idea:** Start with high coupling (rho=0.7), gradually decrease to low coupling (rho=0.1).

**Why Not:**
- Current schedule (low ‚Üí high) validated in original research
- Phase 1 isolation allows foundation building
- Reversing may cause early mode collapse
- No empirical evidence this improves performance

---

## Appendix C: Glossary

**Resolution:** Quality of discrete‚Üícontinuous mapping (reconstruction accuracy)

**Coverage:** Percentage of 19,683 operations reachable via prior sampling

**Complementarity:** Degree to which VAE-A and VAE-B specialize in different operations

**Ensemble:** Combining outputs of both VAEs for improved performance

**Rho (œÅ):** Cross-injection permeability (0 = isolated, 1 = fully coupled)

**Phase-Scheduled Training:** Four-phase training with different coupling strengths

**StateNet:** Meta-controller that adapts hyperparameters during training

**Ternary Operation:** 2-input logic function with 9-element truth table, values ‚àà {-1, 0, 1}

**Manifold:** Continuous latent space learned by VAE (16-dimensional)

**Latent Coupling:** Correlation between VAE-A and VAE-B latent representations

---

## Conclusion

This plan provides a validated, systematic approach to improving the ternary manifold resolution from current baseline (epoch 3: ensemble 100% reconstruction, 84.80% coverage) toward sustained high-resolution performance throughout all training phases.

**Key Strengths:**
- ‚úÖ All recommendations validated through benchmarking
- ‚úÖ Clear success criteria and risk mitigation
- ‚úÖ Realistic timeline and resource estimates
- ‚úÖ Explicit cache management (Appendix A)
- ‚úÖ Alternative approaches evaluated (Appendix B)

**Next Steps:**
1. Review and approve plan
2. Begin implementation (Week 1, Day 1)
3. Execute according to timeline
4. Monitor progress against success criteria
5. Adapt based on empirical findings

**Expected Outcome:** By epoch 400, achieve VAE-A reconstruction 90%+, ensemble 100%, coverage 90%+, and balanced complementarity (0.60+), establishing a production-ready system with complete ternary manifold resolution.

---

**Plan Version:** 1.0
**Date:** 2025-11-24
**Status:** READY FOR IMPLEMENTATION
**Approval:** Pending
