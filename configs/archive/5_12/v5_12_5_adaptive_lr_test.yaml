# V5.12.5 Adaptive LR Scheduler Test
# Test Phase 2.3 optimization: Validation-based learning rate scheduling

device:
  name: v5_12_5_adaptive_lr_test
  cuda_device: 0
  use_amp: false
  pin_memory: true
  num_workers: 4
  empty_cache_freq: 25

torch_compile:
  enabled: true
  backend: eager
  mode: default
  fullgraph: false

gradient_checkpoint:
  enabled: true
  preserve_rng_state: true
  segments: 2
  use_reentrant: true
  encoder_checkpoint: true
  decoder_checkpoint: true
  projection_checkpoint: false
  controller_checkpoint: false

mixed_precision:
  enabled: true
  dtype: float16
  init_scale: 65536.0
  growth_factor: 2.0
  backoff_factor: 0.5
  growth_interval: 2000

model:
  name: TernaryVAEV5_11_PartialFreeze
  latent_dim: 16
  hidden_dim: 64
  max_radius: 0.95
  curvature: 1.0
  use_controller: true
  use_dual_projection: true
  learnable_curvature: true
  manifold_aware: true
  projection_layers: 2
  projection_dropout: 0.1
  encoder_type: improved
  decoder_type: improved
  encoder_dropout: 0.1
  decoder_dropout: 0.1
  logvar_min: -10.0
  logvar_max: 2.0

option_c:
  enabled: true
  encoder_b_lr_scale: 0.1
  encoder_a_lr_scale: 0.05

frozen_checkpoint:
  path: sandbox-training/checkpoints/v5_12_4/best_Q.pt
  encoder_to_load: both
  decoder_to_load: decoder_A

homeostasis:
  enabled: true
  coverage_freeze_threshold: 0.995
  coverage_unfreeze_threshold: 1.0
  coverage_floor: 0.95
  warmup_epochs: 10
  hysteresis_epochs: 5
  enable_annealing: true
  annealing_step: 0.003
  hierarchy_plateau_threshold: 0.001
  hierarchy_plateau_patience: 15
  hierarchy_patience_ceiling: 30

loss:
  adaptive_loss:
    enabled: true
    enable_curriculum: true
    enable_difficulty_adaptive: true
    enable_performance_rebalancing: true
    curriculum_warmup_epochs: 5
    curriculum_transition_epochs: 8
    rebalancing_interval: 3

  rich_hierarchy:
    enabled: true
    hierarchy_weight: 5.0
    coverage_weight: 1.0
    richness_weight: 2.5
    separation_weight: 3.0
    min_richness_ratio: 0.5
  radial:
    enabled: true
    inner_radius: 0.08
    outer_radius: 0.9
    radial_weight: 1.0
  geodesic:
    enabled: true
    phase_start_epoch: 50
    curvature: 1.0
    max_target_distance: 3.0
    n_pairs: 2000
    weight: 0.5
  rank:
    enabled: true
    weight: 0.5
    temperature: 0.1
  zero_structure:
    enabled: true
    valuation_weight: 0.5
    sparsity_weight: 0.3

riemannian:
  enabled: true
  optimizer: adam

training:
  epochs: 18  # Longer run to test LR scheduling
  batch_size: 512
  lr: 0.001   # Higher initial LR to test reduction
  weight_decay: 0.0001
  max_grad_norm: 1.0
  use_stratified: true
  high_v_budget_ratio: 0.25
  use_adaptive: true
  hierarchy_threshold: -0.75
  patience: 25
  min_epochs: 8

  # NEW: Adaptive LR Scheduler Configuration (Phase 2.3)
  scheduler:
    adaptive_lr:
      enabled: true                         # Enable adaptive LR scheduling
      primary_metric: "hierarchy_correlation"  # Monitor hierarchy improvement
      mode: "max"                           # Higher is better for correlation
      patience: 5                          # Reduce LR after 5 epochs without improvement
      factor: 0.6                          # Reduce LR by 40%
      min_lr: 0.00001                      # Minimum learning rate
      threshold: 0.001                     # Relative improvement threshold
      threshold_mode: "rel"                # Relative threshold mode
      cooldown: 2                          # Wait 2 epochs after LR reduction
      warmup_epochs: 3                     # Start monitoring after 3 epochs
      verbose: true                        # Print LR changes

      # Multi-metric monitoring
      secondary_metrics: ["coverage_accuracy", "richness_ratio"]
      metric_weights:
        hierarchy_correlation: 0.6          # Primary weight
        coverage_accuracy: 0.2              # Secondary importance
        richness_ratio: 0.2                 # Secondary importance

      # Advanced features
      adaptive_patience: true              # Increase patience over time
      recovery_detection: true             # Detect recovery from plateaus
      early_stopping: false               # Disable early stopping for test
      early_stopping_patience: 15         # Would stop after 15 bad epochs

      # Recovery mechanics
      recovery_factor: 1.3                 # Increase LR by 30% when recovering
      recovery_threshold: 0.02             # 2% improvement to trigger recovery

    # Fallback settings for non-adaptive mode
    type: cosine_annealing
    T_max: 50
    eta_min: 0.000001

  eval_every: 2
  save_every: 5
  print_every: 2

data:
  use_full_dataset: true
  n_operations: 19683

logging:
  tensorboard: true
  log_dir: runs/v5_12_5_adaptive_lr_test
  print_every: 2

checkpoints:
  save_dir: sandbox-training/checkpoints/v5_12_5_adaptive_lr
  save_best: true
  best_metric: composite_score
  checkpoint_name: v5_12_5_adaptive_lr

targets:
  coverage: 1.0
  hierarchy_B: -0.83
  richness: 0.006
  r_v9: 0.15