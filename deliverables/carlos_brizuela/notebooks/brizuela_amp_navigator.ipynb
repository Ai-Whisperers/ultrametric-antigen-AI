{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperbolic AMP Navigator\n",
    "\n",
    "## Multi-Objective Antimicrobial Peptide Optimization\n",
    "\n",
    "**Partner:** Carlos Brizuela  \n",
    "**Objective:** Navigate the hyperbolic latent space to design AMPs with high activity and low toxicity\n",
    "\n",
    "### Key Features\n",
    "1. Visualize AMPs in hyperbolic (p-adic) embedding space\n",
    "2. Identify toxic vs non-toxic clusters\n",
    "3. Compute geodesic paths from toxic to safe regions\n",
    "4. Run NSGA-II optimization in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "# Add project root\n",
    "project_root = Path.cwd().parents[1]\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Project imports\n",
    "try:\n",
    "    from scripts.optimization.latent_nsga2 import (\n",
    "        LatentNSGA2, OptimizationConfig, create_mock_objectives\n",
    "    )\n",
    "    print(\"NSGA-II optimizer loaded successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: Could not load optimizer: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load AMP Data\n",
    "\n",
    "Load pre-computed hyperbolic embeddings from StarPepDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Path to processed data\n",
    "data_path = project_root / \"data\" / \"processed\" / \"starpep_hyperbolic.pt\"\n",
    "\n",
    "if data_path.exists():\n",
    "    data = torch.load(data_path)\n",
    "    embeddings = data['embeddings'].numpy()\n",
    "    metadata = data['metadata']\n",
    "    print(f\"Loaded {len(embeddings)} peptides\")\n",
    "    print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
    "else:\n",
    "    # Generate synthetic demo data\n",
    "    print(\"Data not found. Generating demo data...\")\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create two clusters: toxic and non-toxic\n",
    "    n_toxic = 100\n",
    "    n_safe = 200\n",
    "    \n",
    "    toxic_embeddings = np.random.randn(n_toxic, 16) * 0.3 + np.array([1.5] * 16)\n",
    "    safe_embeddings = np.random.randn(n_safe, 16) * 0.4 + np.array([-0.5] * 16)\n",
    "    \n",
    "    embeddings = np.vstack([toxic_embeddings, safe_embeddings])\n",
    "    labels = np.array([1] * n_toxic + [0] * n_safe)\n",
    "    \n",
    "    metadata = pd.DataFrame({\n",
    "        'sequence': [f'PEPTIDE_{i}' for i in range(len(embeddings))],\n",
    "        'toxic': labels,\n",
    "        'activity': np.random.rand(len(embeddings))\n",
    "    })\n",
    "    \n",
    "    print(f\"Generated {len(embeddings)} synthetic peptides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Latent Space\n",
    "\n",
    "Use UMAP/PCA to reduce dimensionality for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce to 2D for visualization\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "print(f\"Variance explained: {pca.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot toxic vs non-toxic\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "if 'toxic' in metadata.columns:\n",
    "    toxic_mask = metadata['toxic'] == 1\n",
    "    \n",
    "    ax.scatter(\n",
    "        embeddings_2d[~toxic_mask, 0], \n",
    "        embeddings_2d[~toxic_mask, 1],\n",
    "        c='green', alpha=0.6, label='Non-toxic', s=50\n",
    "    )\n",
    "    ax.scatter(\n",
    "        embeddings_2d[toxic_mask, 0], \n",
    "        embeddings_2d[toxic_mask, 1],\n",
    "        c='red', alpha=0.6, label='Toxic', s=50\n",
    "    )\n",
    "    \n",
    "    # Add cluster centroids\n",
    "    safe_centroid = embeddings_2d[~toxic_mask].mean(axis=0)\n",
    "    toxic_centroid = embeddings_2d[toxic_mask].mean(axis=0)\n",
    "    \n",
    "    ax.scatter(*safe_centroid, c='darkgreen', s=200, marker='*', label='Safe Center')\n",
    "    ax.scatter(*toxic_centroid, c='darkred', s=200, marker='*', label='Toxic Center')\n",
    "    \n",
    "    # Draw geodesic path (straight line in PCA space)\n",
    "    ax.annotate('', xy=safe_centroid, xytext=toxic_centroid,\n",
    "                arrowprops=dict(arrowstyle='->', color='blue', lw=2))\n",
    "    ax.text((safe_centroid[0] + toxic_centroid[0])/2,\n",
    "            (safe_centroid[1] + toxic_centroid[1])/2 + 0.2,\n",
    "            'Optimization Path', fontsize=10, color='blue')\n",
    "else:\n",
    "    ax.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.6)\n",
    "\n",
    "ax.set_xlabel('PC1', fontsize=12)\n",
    "ax.set_ylabel('PC2', fontsize=12)\n",
    "ax.set_title('AMP Hyperbolic Latent Space', fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run NSGA-II Optimization\n",
    "\n",
    "Optimize latent coordinates to find Pareto-optimal peptides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure optimization\n",
    "config = OptimizationConfig(\n",
    "    latent_dim=16,\n",
    "    population_size=100,\n",
    "    generations=50,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Define objectives (using mocks for demo)\n",
    "objectives = create_mock_objectives()\n",
    "\n",
    "print(f\"Optimization Config:\")\n",
    "print(f\"  Population: {config.population_size}\")\n",
    "print(f\"  Generations: {config.generations}\")\n",
    "print(f\"  Objectives: {len(objectives)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization\n",
    "optimizer = LatentNSGA2(config, objectives)\n",
    "pareto_front = optimizer.run(verbose=True)\n",
    "\n",
    "print(f\"\\nPareto front size: {len(pareto_front)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Pareto front\n",
    "pareto_latents = np.array([ind.latent for ind in pareto_front])\n",
    "pareto_2d = pca.transform(pareto_latents)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Left: Latent space with Pareto solutions\n",
    "ax = axes[0]\n",
    "ax.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.3, c='gray', label='Original')\n",
    "ax.scatter(pareto_2d[:, 0], pareto_2d[:, 1], c='blue', s=100, marker='D', label='Pareto Front')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_title('Pareto-Optimal Solutions in Latent Space')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Objective space\n",
    "ax = axes[1]\n",
    "objectives_arr = np.array([ind.objectives for ind in pareto_front])\n",
    "ax.scatter(objectives_arr[:, 0], objectives_arr[:, 1], c='blue', s=50)\n",
    "ax.set_xlabel('Objective 1 (Reconstruction)')\n",
    "ax.set_ylabel('Objective 2 (Toxicity)')\n",
    "ax.set_title('Pareto Front in Objective Space')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export Best Candidates\n",
    "\n",
    "Export the Pareto-optimal latent vectors for decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results = []\n",
    "for i, ind in enumerate(pareto_front[:20]):  # Top 20\n",
    "    results.append({\n",
    "        'rank': i + 1,\n",
    "        'objective_1': ind.objectives[0],\n",
    "        'objective_2': ind.objectives[1],\n",
    "        'objective_3': ind.objectives[2] if len(ind.objectives) > 2 else np.nan,\n",
    "        **{f'z_{j}': z for j, z in enumerate(ind.latent)}\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_path = project_root / 'results' / 'pareto_peptides_brizuela.csv'\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved results to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading and visualizing AMP embeddings in hyperbolic space\n",
    "2. Identifying toxic vs non-toxic clusters\n",
    "3. Running NSGA-II to find Pareto-optimal solutions\n",
    "4. Exporting candidates for experimental validation\n",
    "\n",
    "**Next Steps:**\n",
    "- Decode latent vectors back to sequences using VAE decoder\n",
    "- Validate predicted peptides with toxicity assays\n",
    "- Iterate based on experimental feedback"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
