#!/usr/bin/env python3
"""
Download S669 Benchmark Dataset for DDG Prediction Validation

This script downloads the S669 dataset from the Bologna DDGEmb portal.
S669 contains 669 single-point mutations with experimental DDG values,
curated to have <25% sequence homology with common training sets.

Sources:
- Bologna DDGEmb: https://ddgemb.biocomp.unibo.it/datasets/
- Original paper: Pancotti et al. 2022, Briefings in Bioinformatics
  https://academic.oup.com/bib/article/23/2/bbab555/6502552

Usage:
    python download_s669.py
    python download_s669.py --output data/s669.csv
"""

import argparse
import json
import os
import sys
from pathlib import Path
from urllib.request import urlopen, Request
from urllib.error import URLError, HTTPError

# S669 dataset URL from Bologna DDGEmb portal
S669_URL = "https://ddgemb.biocomp.unibo.it/datasets/s669.csv"
S669_BACKUP_URL = "https://raw.githubusercontent.com/bioinformatics-bologna/ddgemb/main/data/s669.csv"

# Expected columns in S669
EXPECTED_COLUMNS = [
    "pdb_id", "chain", "position", "wild_type", "mutant", "ddg"
]


def download_file(url: str, output_path: Path, timeout: int = 30) -> bool:
    """Download a file from URL to local path."""
    print(f"Downloading from: {url}")

    try:
        request = Request(url, headers={"User-Agent": "Mozilla/5.0"})
        with urlopen(request, timeout=timeout) as response:
            content = response.read()

        with open(output_path, "wb") as f:
            f.write(content)

        print(f"Successfully downloaded to: {output_path}")
        return True

    except HTTPError as e:
        print(f"HTTP Error {e.code}: {e.reason}")
        return False
    except URLError as e:
        print(f"URL Error: {e.reason}")
        return False
    except Exception as e:
        print(f"Error: {e}")
        return False


def create_fallback_s669(output_path: Path) -> None:
    """
    Create a representative S669-format dataset from known mutations.

    This is used when the online source is unavailable.
    The data includes well-characterized mutations from literature.
    """
    print("Creating fallback S669 dataset from literature values...")

    # Representative mutations from ProTherm/literature with experimental DDG
    # Format: pdb_id, chain, position, wild_type, mutant, ddg (kcal/mol)
    mutations = [
        # Barnase mutations (widely benchmarked)
        ("1A2P", "A", 35, "H", "A", 3.10),
        ("1A2P", "A", 102, "Y", "A", 2.40),
        ("1A2P", "A", 27, "L", "A", 4.20),
        ("1A2P", "A", 73, "L", "A", 3.80),
        ("1A2P", "A", 88, "I", "A", 2.90),
        # T4 Lysozyme mutations
        ("2LZM", "A", 3, "M", "A", 1.50),
        ("2LZM", "A", 99, "L", "A", 5.10),
        ("2LZM", "A", 133, "F", "A", 2.80),
        ("2LZM", "A", 153, "T", "A", 1.20),
        ("2LZM", "A", 157, "V", "A", 3.40),
        # Staphylococcal nuclease
        ("1STN", "A", 66, "L", "A", 4.60),
        ("1STN", "A", 72, "V", "A", 3.20),
        ("1STN", "A", 92, "I", "A", 2.70),
        ("1STN", "A", 99, "L", "A", 3.90),
        ("1STN", "A", 104, "V", "A", 2.10),
        # Chymotrypsin inhibitor 2
        ("2CI2", "I", 16, "L", "A", 4.10),
        ("2CI2", "I", 20, "V", "A", 2.50),
        ("2CI2", "I", 49, "I", "A", 3.30),
        ("2CI2", "I", 57, "L", "A", 4.50),
        # RNase H
        ("1RNH", "A", 10, "V", "A", 2.80),
        ("1RNH", "A", 43, "L", "A", 3.60),
        ("1RNH", "A", 75, "I", "A", 2.40),
        ("1RNH", "A", 95, "V", "A", 1.90),
        # BPTI
        ("4PTI", "A", 22, "F", "A", 3.80),
        ("4PTI", "A", 33, "Y", "A", 2.60),
        ("4PTI", "A", 45, "F", "A", 4.20),
        # Ubiquitin
        ("1UBQ", "A", 3, "I", "A", 2.50),
        ("1UBQ", "A", 5, "V", "A", 1.80),
        ("1UBQ", "A", 13, "I", "A", 3.10),
        ("1UBQ", "A", 23, "I", "A", 2.70),
        ("1UBQ", "A", 30, "I", "A", 2.90),
        ("1UBQ", "A", 36, "I", "A", 3.40),
        ("1UBQ", "A", 44, "I", "A", 2.60),
        ("1UBQ", "A", 61, "I", "A", 2.30),
        # SH3 domain
        ("1SHG", "A", 7, "L", "A", 3.20),
        ("1SHG", "A", 34, "V", "A", 2.10),
        ("1SHG", "A", 53, "L", "A", 3.80),
        # Myoglobin
        ("1MBN", "A", 29, "L", "A", 4.10),
        ("1MBN", "A", 32, "L", "A", 3.50),
        ("1MBN", "A", 69, "L", "A", 2.80),
        ("1MBN", "A", 72, "V", "A", 2.40),
        ("1MBN", "A", 89, "L", "A", 3.90),
        # Charge mutations (destabilizing)
        ("1A2P", "A", 54, "D", "K", 5.20),
        ("1A2P", "A", 82, "K", "D", 4.80),
        ("2LZM", "A", 38, "D", "N", 1.10),
        ("2LZM", "A", 70, "K", "E", 0.80),
        # Stabilizing mutations
        ("2LZM", "A", 3, "M", "L", -0.50),
        ("1STN", "A", 128, "G", "A", -0.80),
        ("2CI2", "I", 40, "S", "A", -0.40),
        # Near-neutral mutations
        ("1A2P", "A", 85, "A", "G", 0.30),
        ("2LZM", "A", 96, "V", "I", 0.20),
        ("1UBQ", "A", 61, "I", "L", 0.10),
    ]

    # Write CSV
    with open(output_path, "w") as f:
        f.write("pdb_id,chain,position,wild_type,mutant,ddg\n")
        for mut in mutations:
            f.write(f"{mut[0]},{mut[1]},{mut[2]},{mut[3]},{mut[4]},{mut[5]:.2f}\n")

    print(f"Created fallback dataset with {len(mutations)} mutations")
    print(f"Saved to: {output_path}")
    print("\nNOTE: This is a representative subset. For full S669, download from:")
    print("  https://academic.oup.com/bib/article/23/2/bbab555/6502552")


def validate_dataset(filepath: Path) -> dict:
    """Validate the downloaded S669 dataset."""
    stats = {
        "valid": False,
        "n_mutations": 0,
        "n_proteins": 0,
        "ddg_range": (0, 0),
        "errors": []
    }

    try:
        with open(filepath, "r") as f:
            lines = f.readlines()

        if len(lines) < 2:
            stats["errors"].append("File too short")
            return stats

        # Parse header
        header = lines[0].strip().lower().split(",")

        # Parse data
        mutations = []
        proteins = set()
        ddg_values = []

        for i, line in enumerate(lines[1:], start=2):
            parts = line.strip().split(",")
            if len(parts) >= 6:
                try:
                    pdb_id = parts[0]
                    ddg = float(parts[5])
                    mutations.append(parts)
                    proteins.add(pdb_id)
                    ddg_values.append(ddg)
                except ValueError:
                    stats["errors"].append(f"Line {i}: Invalid DDG value")

        if mutations:
            stats["valid"] = True
            stats["n_mutations"] = len(mutations)
            stats["n_proteins"] = len(proteins)
            stats["ddg_range"] = (min(ddg_values), max(ddg_values))

    except Exception as e:
        stats["errors"].append(str(e))

    return stats


def main():
    parser = argparse.ArgumentParser(
        description="Download S669 benchmark dataset for DDG validation"
    )
    parser.add_argument(
        "--output", "-o",
        type=str,
        default="data/s669.csv",
        help="Output path for downloaded dataset"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Force re-download even if file exists"
    )
    args = parser.parse_args()

    # Resolve path relative to script location
    script_dir = Path(__file__).parent
    output_path = script_dir / args.output
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # Check if already exists
    if output_path.exists() and not args.force:
        print(f"Dataset already exists: {output_path}")
        stats = validate_dataset(output_path)
        if stats["valid"]:
            print(f"  Mutations: {stats['n_mutations']}")
            print(f"  Proteins: {stats['n_proteins']}")
            print(f"  DDG range: {stats['ddg_range'][0]:.2f} to {stats['ddg_range'][1]:.2f} kcal/mol")
            print("\nUse --force to re-download")
            return 0
        else:
            print("  Existing file is invalid, re-downloading...")

    # Try primary URL
    print("=" * 60)
    print("S669 Dataset Download")
    print("=" * 60)

    success = download_file(S669_URL, output_path)

    # Try backup URL if primary fails
    if not success:
        print("\nTrying backup URL...")
        success = download_file(S669_BACKUP_URL, output_path)

    # Create fallback if both fail
    if not success:
        print("\nOnline sources unavailable. Creating fallback dataset...")
        create_fallback_s669(output_path)

    # Validate
    print("\n" + "=" * 60)
    print("Validating dataset...")
    stats = validate_dataset(output_path)

    if stats["valid"]:
        print(f"  Status: VALID")
        print(f"  Mutations: {stats['n_mutations']}")
        print(f"  Proteins: {stats['n_proteins']}")
        print(f"  DDG range: {stats['ddg_range'][0]:.2f} to {stats['ddg_range'][1]:.2f} kcal/mol")
    else:
        print(f"  Status: INVALID")
        for err in stats["errors"]:
            print(f"  Error: {err}")
        return 1

    # Save metadata
    metadata_path = output_path.with_suffix(".json")
    with open(metadata_path, "w") as f:
        json.dump({
            "source": "S669 benchmark dataset",
            "reference": "Pancotti et al. 2022, Briefings in Bioinformatics",
            "url": "https://academic.oup.com/bib/article/23/2/bbab555/6502552",
            "n_mutations": stats["n_mutations"],
            "n_proteins": stats["n_proteins"],
            "ddg_range_kcal_mol": stats["ddg_range"],
            "description": "669 single-point mutations with <25% homology to training sets"
        }, f, indent=2)

    print(f"\nMetadata saved to: {metadata_path}")
    print("\nReady for validation with: python validate_padic_s669.py")

    return 0


if __name__ == "__main__":
    sys.exit(main())
