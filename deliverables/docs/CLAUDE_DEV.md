# Ultrametric Antigen AI - Developer Reference

**Doc-Type:** AI Context (Developer) · Version 1.0 · 2026-02-03

---

## Architecture Overview

The TernaryVAE embeds 19,683 ternary operations (3^9) into a 16-dimensional hyperbolic Poincaré ball where radial position encodes 3-adic valuation.

**Current Version:** 5.12.5
**Status:** Production-optimized

---

## Dual-Encoder System (v5.11+)

### VAE-A (Coverage Encoder)
- **Role:** Reconstruct all 19,683 operations
- **Behavior:** May learn frequency-based ordering
- **Freezing:** Freeze to preserve coverage while training VAE-B

### VAE-B (Hierarchy Encoder)
- **Role:** Learn hierarchical radial ordering
- **Behavior:** Negative correlation for p-adic structure
- **Training:** Benefits from slower learning rate (encoder_b_lr_scale=0.1)

### DifferentiableController
- **Architecture:** 8→32→32→6 MLP
- **Outputs:** rho, weight_geodesic, beta_A, beta_B, tau
- **Enable:** `use_controller=True`

### HomeostasisController
- **Role:** Training orchestrator for freeze/unfreeze
- **Triggers:** Coverage thresholds, hierarchy plateau detection
- **Q-metric:** `Q = dist_corr + 1.5 × |hierarchy|`

---

## V5.12.5 Production Optimizations

### Performance Gains

| Optimization | Speedup | Implementation |
|--------------|---------|----------------|
| torch.compile | 1.4-2.0x | PyTorch 2.x Inductor |
| Mixed Precision | 2.0x + 20-30% VRAM | FP16 autocast |
| Per-Parameter LR | Better hierarchy | encoder_b_lr_scale=0.1 |
| Grokking Detection | Real-time monitoring | Phase classification |

**Measured:** 57 seconds vs ~2-3 minutes baseline (5 epochs, 19,683 ops)

### Configuration

```yaml
# src/configs/v5_12_4_fixed_checkpoint.yaml
torch_compile:
  enabled: true
  backend: eager
  mode: default

mixed_precision:
  enabled: true
  dtype: float16
  init_scale: 65536.0

option_c:
  enabled: true
  encoder_b_lr_scale: 0.1
  encoder_a_lr_scale: 0.05
```

### Training Command

```bash
python src/scripts/training/train_v5_12.py \
    --config src/configs/v5_12_4_fixed_checkpoint.yaml \
    --epochs 100
```

---

## V5.12.4 Improved Components

`ImprovedEncoder` and `ImprovedDecoder` (`src/models/improved_components.py`):

- SiLU activation (smoother gradients than ReLU)
- LayerNorm for stable training
- Dropout (default 0.1)
- logvar clamping [-10, 2] to prevent KL collapse

**Enable:**
```yaml
encoder_type: improved
decoder_type: improved
```

---

## Key Metrics

| Metric | Definition | Target |
|--------|------------|--------|
| **Coverage** | % of 19,683 ops correctly reconstructed | 100% |
| **Hierarchy** | Spearman(valuation, radius) | -0.83 to -1.0 |
| **Richness** | Avg within-level radius variance | >0.005 |
| **Q-metric** | dist_corr + 1.5×\|hierarchy\| | Maximize |

### Hierarchy Ceiling: -0.8321

The Spearman correlation cannot exceed -0.8321 with any within-level variance because v=0 contains 66.7% of samples (13,122 of 19,683).

---

## Checkpoint Reference

| Checkpoint | Coverage | Hier_B | Use Case |
|------------|:--------:|:------:|----------|
| `homeostatic_rich` | 100% | -0.8321 | DDG, semantic reasoning |
| `v5_12_4/best_Q.pt` | 100% | -0.82 | General purpose |
| `v5_11_structural` | 100% | -0.74 | Contact prediction |
| `v5_11_progressive` | 100% | +0.78 | Compression (frequency-optimal) |
| `v5_5/best.pt` | 97.1% | -0.30 | Foundation topology |

### Dual Manifold Framework

Both manifold types are mathematically valid:

| Type | Hierarchy | Optimizes For |
|------|:---------:|---------------|
| Valuation-optimal | Negative (-0.8 to -1.0) | P-adic semantic structure |
| Frequency-optimal | Positive (+0.6 to +0.8) | Shannon information |

---

## Critical Pattern: Hyperbolic Distance

```python
# CORRECT - Hyperbolic distance from origin
from src.geometry import poincare_distance
origin = torch.zeros_like(z_hyp)
radius = poincare_distance(z_hyp, origin, c=curvature)

# WRONG - Euclidean norm on hyperbolic embeddings
radius = torch.norm(z_hyp, dim=-1)  # DO NOT USE
```

### V5.12.2 Audit Status

- **Core files:** All fixed
- **Research scripts:** ~40 files still use Euclidean norm()
- **Audit docs:** `../../docs/mathematical-foundations/V5_12_2_audit/`

---

## Training Parameters

```python
# Loss weights (from homeostatic_rich)
hierarchy_weight = 5.0      # Push toward target radii
coverage_weight = 1.0       # Maintain reconstruction
richness_weight = 2.0       # Preserve within-level variance
separation_weight = 3.0     # Ensure level ordering

# Freeze strategy
freeze_encoder_a = True     # Preserve coverage
freeze_encoder_b = False    # Allow B to learn hierarchy
encoder_b_lr_scale = 0.1    # Slower adaptation

# Variance control
variance_weight = 50-100    # Higher = more collapse
min_richness_ratio = 0.5    # Keep 50% of original variance
```

---

## File Locations

### Core Model
| Purpose | Location |
|---------|----------|
| Main model | `src/models/ternary_vae.py` |
| Improved components | `src/models/improved_components.py` |
| Homeostasis controller | `src/models/homeostasis.py` |

### Geometry
| Purpose | Location |
|---------|----------|
| Poincaré operations | `src/geometry/` |
| **DEPRECATED** | `src/core/geometry_utils.py` |

### Training
| Purpose | Location |
|---------|----------|
| Main script | `src/scripts/training/train_v5_12.py` |
| Homeostatic rich | `src/scripts/epsilon_vae/train_homeostatic_rich.py` |
| Configs | `src/configs/` |

### Encoders
| Purpose | Location |
|---------|----------|
| TrainableCodonEncoder | `src/encoders/trainable_codon_encoder.py` |
| Codon encoder | `src/encoders/codon_encoder.py` |

---

## Grokking Detection

Real-time training dynamics monitoring:

```python
from src.training.grokking_detector import GrokDetector

grok_detector = GrokDetector()
grok_analysis = grok_detector.update(EpochMetrics(
    epoch=epoch, train_loss=loss, correlation=hierarchy_B
))
# Phases: WARMUP → MEMORIZATION → GROKKING
```

---

## Mixed Precision Training

```python
from src.training.optimizations import MixedPrecisionTrainer, MixedPrecisionConfig

mp_trainer = MixedPrecisionTrainer(MixedPrecisionConfig(
    enabled=True, dtype='float16', init_scale=65536.0
))
```

---

## Per-Parameter Learning Rates

```python
param_groups = [
    {"params": encoder_A_params, "lr": base_lr * 0.05},  # Slower coverage
    {"params": encoder_B_params, "lr": base_lr * 0.10},  # Hierarchy learning
    {"params": projection_params, "lr": base_lr}         # Fast adaptation
]
```

---

## Quick Evaluation

```python
from src.models import TernaryVAEV5_11_PartialFreeze
from src.core import TERNARY
from src.geometry import poincare_distance
from scipy.stats import spearmanr

model = TernaryVAEV5_11_PartialFreeze(
    latent_dim=16, hidden_dim=64, max_radius=0.99,
    curvature=1.0, use_controller=True, use_dual_projection=True
)
model.load_state_dict(torch.load('checkpoints/homeostatic_rich/best.pt')['model_state_dict'])

# Get embeddings
out = model(ops, compute_control=False)

# Compute radii (hyperbolic)
origin = torch.zeros_like(out['z_B_hyp'])
radii_B = poincare_distance(out['z_B_hyp'], origin, c=1.0)

# Compute hierarchy
valuations = TERNARY.valuation(indices)
hierarchy = spearmanr(valuations.cpu(), radii_B.cpu())[0]
```

---

## Partner Packages Integration

All partner packages use `src.core.padic_math` for consistency.

| Package | Key Integration |
|---------|-----------------|
| protein_stability_ddg | TrainableCodonEncoder + Ridge |
| antimicrobial_peptides | PeptideVAE + NSGA-II |
| arbovirus_surveillance | TrainableCodonEncoder + primer design |
| hiv_research_package | Stanford HIVdb API |

---

## Deprecated Modules

**`src/core/geometry_utils.py`** - DEPRECATED as of V5.12.2

```python
# OLD (deprecated)
from src.core.geometry_utils import poincare_distance

# NEW (use this)
from src.geometry import poincare_distance, exp_map_zero
```

---

## Known Issues

- `torch.cuda.amp` deprecation warnings (API migration needed)
- Graph breaks in torch.compile from `.item()` calls (minor)
- ~40 research scripts use Euclidean norm() (low priority)

---

## Remaining Tasks

| Priority | Task |
|:--------:|------|
| 1 | V5.12.2 research script fixes (~40 files) |
| 2 | Partner README updates (usage examples) |
| 3 | Fix tier numbering in docs |
| 4 | Publication figures organization |

---

## External APIs

**AlphaFold API** - Sunset **2026-06-25**. Use `modelEntityId` not `entryId`.

---

## Documentation Links

| Document | Purpose |
|----------|---------|
| [CLAUDE_BIO.md](CLAUDE_BIO.md) | Bioinformatics applications |
| [CLAUDE_LITE.md](CLAUDE_LITE.md) | Quick reference |
| [Mathematical Foundations](../../docs/mathematical-foundations/) | Deep theory |
| [V5.12.2 Audit](../../docs/mathematical-foundations/V5_12_2_audit/) | Hyperbolic fixes |

---

*For mathematical theory: [../../docs/mathematical-foundations/](../../docs/mathematical-foundations/)*
*Original full context: [../../docs/mathematical-foundations/archive/CLAUDE_ORIGINAL.md](../../docs/mathematical-foundations/archive/CLAUDE_ORIGINAL.md)*
